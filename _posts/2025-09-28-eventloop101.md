---
title: "Node.js por Trás do Event Loop e Worker Threads"
date: 2025-09-28 02:49:28
tags:
---

Falar de event loop e worker threads é pré-requisito quando planejamos (e até mesmo executamos) aplicações escaláveis com Node.js, vejo muitas alusões (como usar o exemplo do  while(true)) e tentavivas de tornar mais "humano" (como usar o exemplo da fila), mas vou seguir pra algo utilizando os nomes propriamente.

Acredito que o mais dificil seja a quantidade de peças que precisamos encaixar nesse quebra-cabeça, então vamos separar o que vemos sendo chamado de event loop em seus devidos passos, todo processo de execução assincrono de um programa JavaScript seguirá esse caminho:

- entrar na call stack
- sair da call stack e delegar execução assincrona para o ambiente do Node.js
- quando finalizado, o resultado é colocado na task queue (para callbacks comuns e operações de I/O)
- em caso de promise, o resultado vai para a microtask queue

* event loop checa se não tem nada na microtask queue antes de adicionar uma execução da task queue no call stack

E todo processamento sincrono seguirá esse caminho:

- entrar na call stack
- sair da call stack e executar

Entendendo as peças

Bom, agora conhecemos os nomes e temos um conhecimento insuficiente do que cada um faz, então vamos aprofundar.

## Call stack, task queue, microtask queue e event loop

A call stack, em tradução pilha de chamada, é uma pilha de execuções. O Node.js é desenvolvido utilizando a Libuv, que é single-threaded, o que facilita entender essa pilha, não temos operações em paralelo, temos uma chamada após a outra.

Mas existe uma pegadinha: quando falamos que uma chamada é após a outra, não quer dizer o código roda de forma sequencial até o fim, quer dizer que a call stack delega, de maneira síncrona, para as outras estruturas (como task queue e microtask queue).

No exemplo a seguir temos duas execuções que entram sequencialmente e são endereçadas dessa forma, mas não executam nessa sequencia:

```typescript
setTimeout(() => console.log("Estou no setTimeout"), 100)

Promise.resolve().then(() => console.log("Estou na Promise"))

console.log("Estou após a Promise e o setTimeout")
```

Isso nos gera o seguinte output:

```bash
Estou após a Promise e o setTimeout
Estou na Promise
Estou no setTimeout
```

A explicação pra isso é: 

- o setTimeout entrará na call stack, e será prontamente direcionado a execução em background (usando Node.js para gerenciar o tempo "fisico").

- o Promise.resolve() entrará na call stack e será prontamente executado, mas o callback .then() será delegado ao microtask queue

- o event loop esvaziará a microtask queue

- `console.log("Estou após o setTimeout")` entrará na call stack, e será executado, pois é sincrono. 

- após 100ms a execução do `console.log("Estou no setTimeout")` irá para a task queue

- por fim o event loop esvaziará a task queue, adicionando ao call stack para ser executado.

## Riscos

Quando comecei a utilizar Node.js, escutei muito sobre ser não bloqueante em termos de I/O, e isso, com certeza, me gerou confusão. Outro problema que tive com termos foi quando escutava sobre as opções para "multi-threading" com Node.js e pensava ser algo da estrutura. Vamos entender esses dois conceitos e como isso leva nossos sistemas a grandes falhas.

# Non-blocking I/O

Como vimos na explicação do event loop, operações de I/O saem do call stack e são delegadas para processamento em background, enquanto a call stack segue livre para executar novas chamadas. 

Quando a operação de I/O é concluída, a callback associada é colocada na task queue ou, se estiver ligada a uma Promise, na microtask queue, aguardando sua vez de ser executada pelo event loop. 

Com isso, conseguimos ler o disco, fazer chamadas de rede, utilizar timers, entre outras operações assíncronas, sem bloquear nossa call stack de processar e endereçar novas chamadas.

# Single-threaded

Aqui talvez surja a maior confusão: o Node.js oferece formas de paralelismo, como as Worker Threads, mas a call stack continua sendo single-threaded.

Nesse caso, tudo que entrar e for processado de forma síncrona precisará concluir a execução antes da próxima operação na call stack. É aqui que reside o grande risco do Node.js:

- Se eu fizer uma chamada ao banco de dados que demorar 10s, a operação de I/O é non-blocking, já que o retorno virá via Promise, seguindo a microtask queue; assim, a call stack já estará liberada, e só retornaremos para entregar a Promise resolvida.

- Se eu realizar uma operação CPU-intensive, como um for-loop para verificar se meus 4,5 milhões de usuários têm a letra "A" no nome e agrupá-los, a call stack só será liberada para a próxima execução após a conclusão desse for-loop.

# Worker Threads

As Worker Threads são uma solução robusta e nativa, tendo como principal crítica, provavelmente, a experiência do desenvolvedor (DX), mas resolvem o problema de processamento de operações síncronas pesadas, separando-as em um novo event loop, com call stack e todas as filas independentes.

Vamos testar duas abordagens do mesmo algoritmo, que agrupa strings de um arquivo de acordo com letras do alfabeto e expõe o resultado via endpoint HTTP: uma versão sem Worker Threads e outra com Worker Threads. 

* Disclaimer: nenhuma das versões terá preocupação de otimizar consumo de recursos, o foco aqui é entender como não bloquear a call stack (e por consequência as respostas da nossa API HTTP) por meio de Worker Threads.

Exemplo:

```
a: 10
b: 5
```

# Versão sem Worker Threads 

Bloqueia a call stack; durante a execução, tente fazer um `GET /outra-api`, deve ficar com a requisição presa.

api.js
```typescript
import Fastify from 'fastify'
import { readFile } from 'fs/promises'

const app = Fastify()

const path = 'caminho-ate-arquivo/arquivo-gigante.txt'

app.get('/operacao-assincrona-pesada', async (req, reply) => {
  const data = await readFile(path, 'utf8')

  const text = data.toLowerCase()
  const alphabet = 'abcdefghijklmnopqrstuvwxyz'
  const counts = {}
  
  for (const letter of alphabet) counts[letter] = 0
  
  for (const char of text) {
    if (alphabet.includes(char)) counts[char]++
  }

  return { length: data.length, counts }
})

app.get('/outra-api', async () => 'Sou a outra API respondendo!')


app.listen({ port: 3000 })
```

# Versão com Worker Threads

Não bloqueia a call stack; durante a execução, tente fazer um `GET /outra-api`, deve continuar respondendo.

AlphabetGroupWorker.js
```typescript
import { parentPort, workerData } from 'worker_threads'

const text = workerData.toLowerCase()
const alphabet = 'abcdefghijklmnopqrstuvwxyz'
const counts = {}

for (const letter of alphabet) counts[letter] = 0

for (const char of text) {
  if (alphabet.includes(char)) counts[char]++
}

parentPort.postMessage(counts)
```

E usamos esse worker no nosso endpoint. Aqui provavelmente está a maior crítica à experiência do desenvolvedor (DX):

api.js
```typescript
import Fastify from 'fastify'
import { readFile } from 'fs/promises'
import { Worker } from 'worker_threads'

const app = Fastify()

const path = 'caminho-ate-arquivo/arquivo-gigante.txt'

app.get('/operacao-assincrona-pesada', async (req, reply) => {
  const data = await readFile(path, 'utf8')

  const counts = await new Promise((resolve, reject) => {
    const worker = new Worker('./AlphabetGroupWorker.js', { 
      workerData: data 
    })

    worker.on('message', resolve)
    worker.on('error', reject)
    worker.on('exit', code => {
      if (code !== 0) reject(new Error(`AlphabeticGroupWorker parou com código (exit code): ${code}`))
    })
  })  

  return { length: data.length, counts }
})

app.get('/outra-api', async () => 'Sou a outra API respondendo!')


app.listen({ port: 3000 })
```

Essa abordagem não bloquearia a call stack, e ainda podemos tentar centralizar a execução do Worker Thread para melhorar a experiência.

```typescript
export function runWorker(file, workerData) {
  return new Promise((resolve, reject) => {

    const worker = new Worker(file, { workerData })

    worker.on('message', resolve)
    worker.on('error', reject)
    worker.on('exit', code => {
      if (code !== 0) reject(new Error(`Worker parou com código ${code}`))
    })
  })
}
```

E quem utilizar o Worker Thread pode invocar com:

```typescript
const counts = await runWorker('./AlphabetGroupWorker.js', data) 
```

## Conclusão

Vimos como os componentes do ciclo de execução de um programa JavaScript se comportam e interagem, quais execuções agendam ações na task queue e na microtask queue, e como as operações assíncronas são executadas em background pelo Node.js. Também aprendemos como lidar com operações CPU-intensive sem travar a call stack, utilizando Worker Threads.

## Referências

[Improving the scalability of Node.js applications in the cloud by integrating parallel processing and multi-threading, followed by a performance assessment across AWS, GCP cloud platforms](https://norma.ncirl.ie/8003)

[Video - JavaScript Visualized - Event Loop, Web APIs, (Micro)task Queue](https://www.youtube.com/watch?v=eiC58R16hb8)